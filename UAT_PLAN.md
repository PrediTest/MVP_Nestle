# Plano de Testes de Aceita√ß√£o do Usu√°rio (UAT)
## PrediTest AI (Aegis) - Valida√ß√£o em Produ√ß√£o

---

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Objetivos do UAT](#objetivos-do-uat)
3. [Escopo e Limites](#escopo-e-limites)
4. [Equipe e Responsabilidades](#equipe-e-responsabilidades)
5. [Cronograma](#cronograma)
6. [Ambiente de Teste](#ambiente-de-teste)
7. [Casos de Teste](#casos-de-teste)
8. [Crit√©rios de Aceita√ß√£o](#crit√©rios-de-aceita√ß√£o)
9. [Procedimentos de Teste](#procedimentos-de-teste)
10. [Relat√≥rio de Defeitos](#relat√≥rio-de-defeitos)
11. [M√©tricas e KPIs](#m√©tricas-e-kpis)
12. [Aprova√ß√£o e Sign-off](#aprova√ß√£o-e-sign-off)

---

## üéØ Vis√£o Geral

O Plano de Testes de Aceita√ß√£o do Usu√°rio (UAT) define a estrat√©gia, escopo e procedimentos para validar que a aplica√ß√£o PrediTest AI atende aos requisitos de neg√≥cio e est√° pronta para uso em produ√ß√£o pela Nestl√© Brasil.

### Informa√ß√µes B√°sicas

| Item | Descri√ß√£o |
|------|-----------|
| **Aplica√ß√£o** | PrediTest AI (Aegis) |
| **Vers√£o** | 1.0.0 |
| **Ambiente** | Produ√ß√£o |
| **Data In√≠cio** | [Data de In√≠cio] |
| **Data Fim** | [Data de Fim] |
| **Dura√ß√£o Estimada** | 2-3 semanas |
| **Respons√°vel** | Gestor de Projeto Nestl√© |

---

## üéØ Objetivos do UAT

### Objetivos Prim√°rios

1. **Validar Funcionalidades**
   - Confirmar que todas as funcionalidades funcionam conforme especificado
   - Validar fluxos de neg√≥cio end-to-end
   - Testar integra√ß√£o com sistemas externos

2. **Validar Requisitos N√£o-Funcionais**
   - Performance e escalabilidade
   - Seguran√ßa e conformidade
   - Usabilidade e experi√™ncia do usu√°rio
   - Disponibilidade e confiabilidade

3. **Identificar Problemas**
   - Detectar defeitos cr√≠ticos
   - Identificar gaps funcionais
   - Documentar comportamentos inesperados

4. **Obter Aprova√ß√£o**
   - Confirmar readiness para produ√ß√£o
   - Obter sign-off de stakeholders
   - Documentar decis√µes

### Objetivos Secund√°rios

- Treinar usu√°rios finais
- Documentar procedimentos operacionais
- Estabelecer baseline de performance
- Validar planos de backup e disaster recovery

---

## üìä Escopo e Limites

### Dentro do Escopo

‚úÖ Testes de funcionalidades principais
‚úÖ Testes de fluxos de neg√≥cio cr√≠ticos
‚úÖ Testes de integra√ß√£o com APIs externas
‚úÖ Testes de performance sob carga
‚úÖ Testes de seguran√ßa b√°sicos
‚úÖ Testes de usabilidade
‚úÖ Testes de dados e relat√≥rios
‚úÖ Testes de backup e recovery

### Fora do Escopo

‚ùå Testes de carga extrema (stress testing)
‚ùå Testes de penetra√ß√£o avan√ßados
‚ùå Testes de compatibilidade de browsers antigos
‚ùå Testes de acessibilidade completa (WCAG)
‚ùå Testes de internacionaliza√ß√£o
‚ùå Testes de mobile (vers√£o desktop)

---

## üë• Equipe e Responsabilidades

### Estrutura da Equipe

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Patrocinador do Projeto                    ‚îÇ
‚îÇ        (Diretor Inova√ß√£o Nestl√© Brasil)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ            ‚îÇ            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Gestor    ‚îÇ ‚îÇ L√≠der   ‚îÇ ‚îÇ L√≠der   ‚îÇ
‚îÇ Projeto    ‚îÇ ‚îÇ Testes  ‚îÇ ‚îÇ Neg√≥cio ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ           ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ               ‚îÇ            ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ Tester ‚îÇ      ‚îÇ Tester  ‚îÇ  ‚îÇUsu√°rio ‚îÇ
      ‚îÇ   QA   ‚îÇ      ‚îÇ  Func   ‚îÇ  ‚îÇ Final  ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Responsabilidades

| Papel | Responsabilidades |
|------|------------------|
| **Patrocinador** | Aprova√ß√£o final, resolu√ß√£o de escala√ß√µes, autoriza√ß√£o de go-live |
| **Gestor de Projeto** | Coordena√ß√£o geral, cronograma, comunica√ß√£o |
| **L√≠der de Testes** | Planejamento de testes, coordena√ß√£o de testadores, relat√≥rios |
| **Testador QA** | Execu√ß√£o de testes t√©cnicos, documenta√ß√£o de defeitos |
| **Testador Funcional** | Testes de neg√≥cio, valida√ß√£o de fluxos |
| **Usu√°rio Final** | Testes de usabilidade, valida√ß√£o de requisitos |

---

## üìÖ Cronograma

### Fases do UAT

```
Semana 1: Prepara√ß√£o e Setup
‚îú‚îÄ Dia 1-2: Prepara√ß√£o do ambiente
‚îú‚îÄ Dia 3-4: Treinamento da equipe
‚îî‚îÄ Dia 5: Smoke testing

Semana 2: Testes Funcionais
‚îú‚îÄ Dia 1-2: Testes de funcionalidades principais
‚îú‚îÄ Dia 3-4: Testes de fluxos de neg√≥cio
‚îî‚îÄ Dia 5: Testes de integra√ß√£o

Semana 3: Testes N√£o-Funcionais
‚îú‚îÄ Dia 1-2: Testes de performance
‚îú‚îÄ Dia 3: Testes de seguran√ßa
‚îú‚îÄ Dia 4: Testes de usabilidade
‚îî‚îÄ Dia 5: Testes de dados

Semana 4: Valida√ß√£o Final
‚îú‚îÄ Dia 1-2: Testes de regress√£o
‚îú‚îÄ Dia 3: Testes de backup/recovery
‚îú‚îÄ Dia 4: Corre√ß√£o de defeitos
‚îî‚îÄ Dia 5: Sign-off e aprova√ß√£o
```

### Marcos Importantes

| Data | Milestone | Respons√°vel |
|------|-----------|-------------|
| D+0 | Ambiente pronto | DevOps |
| D+2 | Equipe treinada | Gestor Projeto |
| D+5 | Smoke testing completo | L√≠der Testes |
| D+10 | Testes funcionais 80% | Testadores |
| D+15 | Testes n√£o-funcionais 100% | Testadores |
| D+20 | Todos os defeitos cr√≠ticos resolvidos | Dev Team |
| D+21 | UAT aprovado | Patrocinador |

---

## üè¢ Ambiente de Teste

### Configura√ß√£o do Ambiente

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Ambiente de Produ√ß√£o (UAT)                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                      ‚îÇ
‚îÇ  Frontend: https://preditest-ai-uat.nestle.com.br  ‚îÇ
‚îÇ  Backend: API tRPC em /api/trpc                     ‚îÇ
‚îÇ  Database: PostgreSQL 15 (dados de teste)           ‚îÇ
‚îÇ  Cache: Redis cluster (3 nodes)                     ‚îÇ
‚îÇ  Storage: S3 (dados de teste)                       ‚îÇ
‚îÇ                                                      ‚îÇ
‚îÇ  Monitoramento:                                      ‚îÇ
‚îÇ  - Prometheus: http://prometheus-uat:9090           ‚îÇ
‚îÇ  - Grafana: http://grafana-uat:3000                 ‚îÇ
‚îÇ  - ELK Stack: http://kibana-uat:5601                ‚îÇ
‚îÇ                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Dados de Teste

```
Usu√°rios de Teste:
‚îú‚îÄ admin@nestle.com.br (Admin)
‚îú‚îÄ gerente@nestle.com.br (Gerente)
‚îú‚îÄ analista@nestle.com.br (Analista)
‚îî‚îÄ operador@nestle.com.br (Operador)

Dados de Teste:
‚îú‚îÄ 5 projetos de teste
‚îú‚îÄ 100+ registros de dados de manufatura
‚îú‚îÄ 50+ standards pr√©-carregados
‚îú‚îÄ 30+ reclama√ß√µes de consumidores
‚îú‚îÄ 20+ alertas simulados
‚îî‚îÄ 10+ relat√≥rios de exemplo
```

### Acesso e Credenciais

| Componente | URL | Usu√°rio | Senha |
|-----------|-----|--------|-------|
| Aplica√ß√£o | https://preditest-ai-uat.nestle.com.br | admin@nestle.com.br | [Senha Segura] |
| Grafana | http://grafana-uat:3000 | admin | [Senha Segura] |
| Kibana | http://kibana-uat:5601 | elastic | [Senha Segura] |
| DB | preditest-ai-db-uat | dbuser | [Senha Segura] |

---

## üß™ Casos de Teste

### 1. Testes de Autentica√ß√£o e Autoriza√ß√£o

#### TC-AUTH-001: Login com Credenciais V√°lidas
```
Pr√©-condi√ß√£o: Usu√°rio n√£o autenticado
Passos:
1. Acessar p√°gina de login
2. Inserir email: admin@nestle.com.br
3. Inserir senha: [senha v√°lida]
4. Clicar em "Entrar"

Resultado Esperado:
- Usu√°rio autenticado com sucesso
- Redirecionado para dashboard
- Sess√£o criada com JWT v√°lido
- Informa√ß√µes do usu√°rio exibidas no header

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-AUTH-002: Login com Credenciais Inv√°lidas
```
Pr√©-condi√ß√£o: Usu√°rio n√£o autenticado
Passos:
1. Acessar p√°gina de login
2. Inserir email: admin@nestle.com.br
3. Inserir senha: [senha inv√°lida]
4. Clicar em "Entrar"

Resultado Esperado:
- Mensagem de erro exibida
- Usu√°rio n√£o autenticado
- Permanece na p√°gina de login

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-AUTH-003: Logout
```
Pr√©-condi√ß√£o: Usu√°rio autenticado
Passos:
1. Clicar no menu do usu√°rio (header)
2. Clicar em "Sair"

Resultado Esperado:
- Sess√£o encerrada
- Redirecionado para p√°gina de login
- Cookie de sess√£o removido

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-AUTH-004: Acesso Negado sem Autentica√ß√£o
```
Pr√©-condi√ß√£o: Usu√°rio n√£o autenticado
Passos:
1. Tentar acessar URL protegida diretamente
2. Ex: /projetos, /dashboard

Resultado Esperado:
- Redirecionado para p√°gina de login
- Mensagem de acesso negado exibida

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

### 2. Testes de Funcionalidades Principais

#### TC-PROJ-001: Criar Novo Projeto
```
Pr√©-condi√ß√£o: Usu√°rio autenticado com permiss√£o
Passos:
1. Navegar para "Projetos"
2. Clicar em "Novo Projeto"
3. Preencher formul√°rio:
   - Nome: "Teste UAT Produto X"
   - Descri√ß√£o: "Projeto de teste para UAT"
   - F√°brica: "S√£o Paulo - SP"
   - Tipo: "Lan√ßamento"
   - Risco Inicial: "35"
4. Clicar em "Salvar"

Resultado Esperado:
- Projeto criado com sucesso
- Exibir mensagem de confirma√ß√£o
- Projeto aparece na lista
- ID do projeto gerado
- Timestamp de cria√ß√£o registrado

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-PROJ-002: Editar Projeto
```
Pr√©-condi√ß√£o: Projeto existente
Passos:
1. Navegar para "Projetos"
2. Clicar em projeto existente
3. Clicar em "Editar"
4. Alterar nome para "Teste UAT Produto X - Atualizado"
5. Clicar em "Salvar"

Resultado Esperado:
- Altera√ß√µes salvas com sucesso
- Mensagem de confirma√ß√£o exibida
- Dados atualizados na lista
- Timestamp de atualiza√ß√£o registrado

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-PROJ-003: Deletar Projeto
```
Pr√©-condi√ß√£o: Projeto existente sem dados cr√≠ticos
Passos:
1. Navegar para "Projetos"
2. Clicar em projeto
3. Clicar em "Deletar"
4. Confirmar exclus√£o

Resultado Esperado:
- Projeto removido com sucesso
- Mensagem de confirma√ß√£o exibida
- Projeto n√£o aparece mais na lista
- Dados removidos do banco

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-DATA-001: Registrar Dados de Manufatura
```
Pr√©-condi√ß√£o: Projeto ativo
Passos:
1. Navegar para projeto
2. Clicar em "Adicionar Dados"
3. Preencher formul√°rio:
   - Data: [Data atual]
   - Linha: "A3"
   - Taxa de Defeitos: "2.1%"
   - Conformidade FDA: "98.5%"
   - Conformidade ISO: "99.2%"
4. Clicar em "Salvar"

Resultado Esperado:
- Dados registrados com sucesso
- Exibir em gr√°ficos/tabelas
- Alertas gerados se necess√°rio
- Timestamp registrado

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-ALERT-001: Gerar Alerta de Risco
```
Pr√©-condi√ß√£o: Dados com risco elevado registrados
Passos:
1. Registrar dados com taxa de defeitos > 2.0%
2. Sistema deve detectar e criar alerta

Resultado Esperado:
- Alerta criado automaticamente
- Exibido no dashboard
- Notifica√ß√£o enviada
- Severidade: "warning"

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-REPORT-001: Gerar Relat√≥rio
```
Pr√©-condi√ß√£o: Projeto com dados
Passos:
1. Navegar para "Relat√≥rios"
2. Selecionar projeto
3. Selecionar per√≠odo (√∫ltimos 30 dias)
4. Clicar em "Gerar Relat√≥rio"

Resultado Esperado:
- Relat√≥rio gerado em PDF
- Cont√©m gr√°ficos e m√©tricas
- Download autom√°tico
- Timestamp inclu√≠do

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

### 3. Testes de Fluxos de Neg√≥cio

#### TC-FLOW-001: Fluxo Completo de Teste de Produto
```
Pr√©-condi√ß√£o: Nenhuma
Passos:
1. Fazer login
2. Criar novo projeto
3. Registrar dados de manufatura
4. Visualizar dashboard
5. Gerar alerta
6. Visualizar alerta
7. Gerar relat√≥rio
8. Fazer logout

Resultado Esperado:
- Todos os passos executados com sucesso
- Dados consistentes em todo fluxo
- Sem erros ou exce√ß√µes
- Performance aceit√°vel

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-FLOW-002: Fluxo de An√°lise Preditiva
```
Pr√©-condi√ß√£o: Projeto com 30+ dias de dados
Passos:
1. Navegar para "An√°lise Preditiva"
2. Selecionar projeto
3. Clicar em "Executar An√°lise"
4. Aguardar processamento
5. Visualizar resultados

Resultado Esperado:
- An√°lise executada com sucesso
- Resultados exibidos em < 30 segundos
- Gr√°ficos com previs√µes
- Score de confian√ßa exibido

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

### 4. Testes de Performance

#### TC-PERF-001: Tempo de Carregamento da P√°gina
```
Pr√©-condi√ß√£o: Usu√°rio autenticado
Passos:
1. Medir tempo de carregamento de:
   - Dashboard: < 2 segundos
   - Projetos: < 2 segundos
   - Relat√≥rios: < 3 segundos
   - An√°lise Preditiva: < 5 segundos

Resultado Esperado:
- Todos os tempos dentro dos limites
- Sem timeouts
- Sem erros de carregamento

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-PERF-002: Performance com M√∫ltiplos Usu√°rios
```
Pr√©-condi√ß√£o: Ambiente de teste
Passos:
1. Simular 50 usu√°rios simult√¢neos
2. Cada usu√°rio executa fluxo b√°sico
3. Medir:
   - Tempo de resposta m√©dio
   - Taxa de erro
   - CPU/Mem√≥ria

Resultado Esperado:
- Tempo de resposta P95 < 500ms
- Taxa de erro < 0.1%
- CPU < 80%
- Mem√≥ria < 85%

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-PERF-003: Consulta de Grande Volume de Dados
```
Pr√©-condi√ß√£o: 10.000+ registros no banco
Passos:
1. Executar relat√≥rio com todos os dados
2. Medir tempo de execu√ß√£o
3. Medir consumo de recursos

Resultado Esperado:
- Relat√≥rio gerado em < 10 segundos
- CPU pico < 90%
- Mem√≥ria < 1GB
- Sem timeout

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

### 5. Testes de Seguran√ßa

#### TC-SEC-001: SQL Injection
```
Pr√©-condi√ß√£o: Formul√°rio de busca
Passos:
1. Inserir payload SQL: ' OR '1'='1
2. Tentar executar busca

Resultado Esperado:
- Entrada sanitizada
- Sem acesso a dados n√£o autorizados
- Mensagem de erro segura exibida

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-SEC-002: XSS (Cross-Site Scripting)
```
Pr√©-condi√ß√£o: Campo de texto livre
Passos:
1. Inserir payload: <script>alert('XSS')</script>
2. Salvar e visualizar

Resultado Esperado:
- Script n√£o executado
- Conte√∫do exibido como texto
- Sem vulnerabilidades

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-SEC-003: CSRF (Cross-Site Request Forgery)
```
Pr√©-condi√ß√£o: Usu√°rio autenticado
Passos:
1. Tentar executar a√ß√£o de outro site
2. Verificar token CSRF

Resultado Esperado:
- Requisi√ß√£o rejeitada
- Token validado
- Sem a√ß√£o executada

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-SEC-004: Acesso a Dados N√£o Autorizados
```
Pr√©-condi√ß√£o: Usu√°rio com permiss√£o limitada
Passos:
1. Tentar acessar dados de outro usu√°rio
2. Tentar modificar dados protegidos
3. Tentar deletar dados cr√≠ticos

Resultado Esperado:
- Acesso negado
- Mensagem de erro apropriada
- A√ß√£o n√£o executada
- Log de tentativa registrado

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

### 6. Testes de Usabilidade

#### TC-UX-001: Navega√ß√£o Intuitiva
```
Pr√©-condi√ß√£o: Usu√°rio novo na aplica√ß√£o
Passos:
1. Usu√°rio tenta executar tarefa comum sem treinamento
2. Observar se consegue completar em < 2 minutos

Resultado Esperado:
- Interface clara e intuitiva
- √çcones e labels compreens√≠veis
- Fluxo l√≥gico
- Ajuda dispon√≠vel se necess√°rio

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-UX-002: Responsividade
```
Pr√©-condi√ß√£o: Aplica√ß√£o aberta
Passos:
1. Testar em diferentes resolu√ß√µes:
   - Desktop (1920x1080)
   - Tablet (768x1024)
   - Mobile (375x667)

Resultado Esperado:
- Layout adapta corretamente
- Sem elementos sobrepostos
- Funcionalidade preservada
- Texto leg√≠vel

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-UX-003: Mensagens de Erro
```
Pr√©-condi√ß√£o: Situa√ß√µes de erro
Passos:
1. Provocar erros comuns:
   - Conex√£o perdida
   - Timeout
   - Valida√ß√£o de formul√°rio
   - Permiss√£o negada

Resultado Esperado:
- Mensagens claras e √∫teis
- A√ß√µes sugeridas
- Sem mensagens t√©cnicas confusas
- Op√ß√£o de retry quando apropriado

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

### 7. Testes de Dados e Integridade

#### TC-DATA-001: Integridade de Dados
```
Pr√©-condi√ß√£o: Dados inseridos
Passos:
1. Verificar dados no banco de dados
2. Comparar com dados exibidos na UI
3. Validar tipos de dados

Resultado Esperado:
- Dados consistentes
- Sem corrup√ß√£o
- Tipos corretos
- Relacionamentos mantidos

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

#### TC-DATA-002: Backup e Recovery
```
Pr√©-condi√ß√£o: Dados em produ√ß√£o
Passos:
1. Executar backup
2. Simular falha de dados
3. Restaurar do backup
4. Verificar integridade

Resultado Esperado:
- Backup executado com sucesso
- Restaura√ß√£o completa
- Dados intactos
- Zero perda de dados

Crit√©rio de Aceita√ß√£o: PASS/FAIL
```

---

## ‚úÖ Crit√©rios de Aceita√ß√£o

### Crit√©rios Funcionais

| Crit√©rio | Descri√ß√£o | M√©trica |
|----------|-----------|---------|
| **Funcionalidades** | Todas as funcionalidades funcionam conforme especificado | 100% dos testes passam |
| **Fluxos de Neg√≥cio** | Todos os fluxos cr√≠ticos funcionam end-to-end | 100% dos fluxos validados |
| **Integra√ß√£o** | Integra√ß√£o com sistemas externos funciona | 100% das integra√ß√µes testadas |
| **Dados** | Dados s√£o corretos, consistentes e √≠ntegros | 0 inconsist√™ncias |

### Crit√©rios N√£o-Funcionais

| Crit√©rio | Descri√ß√£o | M√©trica |
|----------|-----------|---------|
| **Performance** | Aplica√ß√£o responde dentro dos limites | P95 < 500ms |
| **Escalabilidade** | Suporta carga esperada | 50+ usu√°rios simult√¢neos |
| **Disponibilidade** | Uptime em produ√ß√£o | ‚â•99.9% |
| **Seguran√ßa** | Sem vulnerabilidades cr√≠ticas | 0 vulnerabilidades cr√≠ticas |
| **Usabilidade** | Interface intuitiva e f√°cil de usar | Score ‚â•4/5 |

### Crit√©rios de Defeitos

| Severidade | Descri√ß√£o | A√ß√£o |
|-----------|-----------|------|
| **Cr√≠tica** | Funcionalidade essencial n√£o funciona | Bloqueia UAT |
| **Alta** | Funcionalidade importante com problema | Deve ser corrigida |
| **M√©dia** | Funcionalidade com problema menor | Pode ser corrigida ap√≥s go-live |
| **Baixa** | Problema cosm√©tico | Pode ser ignorado |

### Crit√©rios de Aprova√ß√£o

‚úÖ **Aprova√ß√£o Requerida Quando:**
- 100% dos testes cr√≠ticos passam
- 95% dos testes funcionais passam
- 100% dos testes de seguran√ßa passam
- 0 defeitos cr√≠ticos abertos
- Performance dentro dos limites
- Todos os stakeholders assinam

‚ùå **Aprova√ß√£o Bloqueada Quando:**
- Defeitos cr√≠ticos abertos
- Performance abaixo dos limites
- Vulnerabilidades de seguran√ßa encontradas
- Funcionalidades essenciais n√£o funcionam

---

## üîÑ Procedimentos de Teste

### Procedimento Padr√£o de Teste

```
1. PREPARA√á√ÉO
   ‚îú‚îÄ Revisar caso de teste
   ‚îú‚îÄ Preparar dados de teste
   ‚îú‚îÄ Configurar ambiente
   ‚îî‚îÄ Registrar estado inicial

2. EXECU√á√ÉO
   ‚îú‚îÄ Executar passos do teste
   ‚îú‚îÄ Observar resultado
   ‚îú‚îÄ Registrar tempo
   ‚îî‚îÄ Capturar screenshots se necess√°rio

3. VALIDA√á√ÉO
   ‚îú‚îÄ Comparar com resultado esperado
   ‚îú‚îÄ Verificar crit√©rios de aceita√ß√£o
   ‚îú‚îÄ Documentar desvios
   ‚îî‚îÄ Classificar resultado (PASS/FAIL)

4. DOCUMENTA√á√ÉO
   ‚îú‚îÄ Registrar resultado no sistema
   ‚îú‚îÄ Adicionar observa√ß√µes
   ‚îú‚îÄ Anexar evid√™ncias
   ‚îî‚îÄ Atualizar status do teste

5. ESCALA√á√ÉO
   ‚îú‚îÄ Se FAIL: Criar ticket de defeito
   ‚îú‚îÄ Se PASS: Marcar como completo
   ‚îú‚îÄ Notificar respons√°veis
   ‚îî‚îÄ Atualizar dashboard
```

### Procedimento de Reporte de Defeitos

```
1. IDENTIFICA√á√ÉO
   ‚îú‚îÄ Descrever o problema
   ‚îú‚îÄ Indicar severidade
   ‚îú‚îÄ Listar passos para reproduzir
   ‚îî‚îÄ Anexar evid√™ncias (screenshots, logs)

2. DOCUMENTA√á√ÉO
   ‚îú‚îÄ ID do defeito: AUTO-GERADO
   ‚îú‚îÄ T√≠tulo: Descritivo e conciso
   ‚îú‚îÄ Descri√ß√£o: Detalhada
   ‚îú‚îÄ Severidade: Cr√≠tica/Alta/M√©dia/Baixa
   ‚îú‚îÄ Status: Novo
   ‚îî‚îÄ Respons√°vel: Dev Team

3. RASTREAMENTO
   ‚îú‚îÄ Acompanhar status
   ‚îú‚îÄ Comunicar progresso
   ‚îú‚îÄ Validar corre√ß√£o
   ‚îî‚îÄ Fechar ticket

4. REGRESS√ÉO
   ‚îú‚îÄ Testar corre√ß√£o
   ‚îú‚îÄ Verificar se n√£o quebrou nada
   ‚îú‚îÄ Atualizar status
   ‚îî‚îÄ Arquivar ticket
```

### Procedimento de Teste de Regress√£o

```
1. IDENTIFICA√á√ÉO
   ‚îú‚îÄ Listar testes afetados
   ‚îú‚îÄ Priorizar testes cr√≠ticos
   ‚îî‚îÄ Estimar esfor√ßo

2. EXECU√á√ÉO
   ‚îú‚îÄ Executar testes selecionados
   ‚îú‚îÄ Documentar resultados
   ‚îú‚îÄ Identificar novos defeitos
   ‚îî‚îÄ Comparar com baseline

3. AN√ÅLISE
   ‚îú‚îÄ Avaliar impacto
   ‚îú‚îÄ Identificar padr√µes
   ‚îú‚îÄ Documentar achados
   ‚îî‚îÄ Comunicar resultados

4. APROVA√á√ÉO
   ‚îú‚îÄ Se OK: Aprovar mudan√ßa
   ‚îú‚îÄ Se FALHA: Rejeitar mudan√ßa
   ‚îî‚îÄ Atualizar documenta√ß√£o
```

---

## üìù Relat√≥rio de Defeitos

### Template de Relat√≥rio de Defeito

```
ID: [AUTO]
Data: [Data de Cria√ß√£o]
Relatado por: [Nome do Testador]
Severidade: [Cr√≠tica/Alta/M√©dia/Baixa]
Status: [Novo/Em An√°lise/Em Corre√ß√£o/Corrigido/Fechado]

T√çTULO:
[T√≠tulo descritivo do defeito]

DESCRI√á√ÉO:
[Descri√ß√£o detalhada do problema]

PASSOS PARA REPRODUZIR:
1. [Passo 1]
2. [Passo 2]
3. [Passo 3]

RESULTADO ESPERADO:
[O que deveria acontecer]

RESULTADO OBSERVADO:
[O que realmente aconteceu]

AMBIENTE:
- Browser: [Chrome/Firefox/Safari]
- SO: [Windows/Mac/Linux]
- Vers√£o da App: [1.0.0]
- Data/Hora: [Data e hora do teste]

EVID√äNCIAS:
- Screenshot: [Anexo 1]
- Log: [Anexo 2]
- Video: [Anexo 3]

IMPACTO:
[Descri√ß√£o do impacto no neg√≥cio]

NOTAS ADICIONAIS:
[Observa√ß√µes relevantes]

ATRIBU√çDO A:
[Desenvolvedor respons√°vel]

DATA ALVO DE CORRE√á√ÉO:
[Data esperada]
```

### Dashboard de Defeitos

| ID | T√≠tulo | Severidade | Status | Respons√°vel | Data Alvo |
|----|--------|-----------|--------|------------|-----------|
| DEF-001 | Login n√£o funciona | Cr√≠tica | Em Corre√ß√£o | Dev-01 | 2025-11-05 |
| DEF-002 | Gr√°fico n√£o renderiza | Alta | Novo | Dev-02 | 2025-11-06 |
| DEF-003 | Typo em label | Baixa | Novo | Dev-03 | 2025-11-10 |

---

## üìä M√©tricas e KPIs

### M√©tricas de Teste

| M√©trica | F√≥rmula | Meta | Frequ√™ncia |
|---------|---------|------|-----------|
| **Taxa de Cobertura** | Testes Executados / Total de Testes | ‚â•95% | Di√°ria |
| **Taxa de Sucesso** | Testes Passados / Testes Executados | ‚â•95% | Di√°ria |
| **Taxa de Defeitos** | Defeitos Encontrados / Testes Executados | <5% | Di√°ria |
| **Defeitos Cr√≠ticos** | N√∫mero de defeitos cr√≠ticos abertos | 0 | Di√°ria |
| **Tempo M√©dio de Corre√ß√£o** | Tempo entre abertura e fechamento | <24h | Semanal |

### Dashboard de M√©tricas

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          DASHBOARD DE TESTES - UAT                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                     ‚îÇ
‚îÇ  Testes Executados:        145 / 150 (96.7%)       ‚îÇ
‚îÇ  Testes Passados:          138 / 145 (95.2%)       ‚îÇ
‚îÇ  Testes Falhados:            7 / 145 (4.8%)        ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  Defeitos Cr√≠ticos:          0 ‚úÖ                   ‚îÇ
‚îÇ  Defeitos Altos:             2 ‚ö†Ô∏è                   ‚îÇ
‚îÇ  Defeitos M√©dios:            5 ‚ÑπÔ∏è                   ‚îÇ
‚îÇ  Defeitos Baixos:            3 ‚ÑπÔ∏è                   ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  Performance P95:        245ms (Meta: 500ms) ‚úÖ     ‚îÇ
‚îÇ  Uptime:                99.95% (Meta: 99.9%) ‚úÖ    ‚îÇ
‚îÇ  Taxa de Erro:           0.02% (Meta: 0.1%) ‚úÖ     ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  Progresso Geral:        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 80%            ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Relat√≥rio Executivo Semanal

| Semana | Testes | Passados | Falhados | Cr√≠ticos | Status |
|--------|--------|----------|----------|----------|--------|
| 1 | 30 | 28 | 2 | 0 | üü° Em Progresso |
| 2 | 60 | 57 | 3 | 0 | üü° Em Progresso |
| 3 | 45 | 43 | 2 | 0 | üü¢ Pronto |
| 4 | 15 | 15 | 0 | 0 | üü¢ Completo |

---

## ‚úçÔ∏è Aprova√ß√£o e Sign-off

### Matriz de Aprova√ß√£o

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Stakeholder        ‚îÇ Fun√ß√£o   ‚îÇ Assinatura ‚îÇ Data     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Diretor Inova√ß√£o   ‚îÇ Aprova   ‚îÇ __________ ‚îÇ ________ ‚îÇ
‚îÇ Gerente de Projeto ‚îÇ Valida   ‚îÇ __________ ‚îÇ ________ ‚îÇ
‚îÇ L√≠der de Testes    ‚îÇ Certifica‚îÇ __________ ‚îÇ ________ ‚îÇ
‚îÇ Representante TI   ‚îÇ Aprova   ‚îÇ __________ ‚îÇ ________ ‚îÇ
‚îÇ Representante Neg. ‚îÇ Aprova   ‚îÇ __________ ‚îÇ ________ ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Crit√©rios de Sign-off

**Pr√©-requisitos para Sign-off:**

‚úÖ 100% dos testes cr√≠ticos passam
‚úÖ 95% dos testes funcionais passam
‚úÖ 100% dos testes de seguran√ßa passam
‚úÖ 0 defeitos cr√≠ticos abertos
‚úÖ Performance dentro dos limites
‚úÖ Backup e recovery validados
‚úÖ Monitoramento ativo
‚úÖ Plano de rollback documentado
‚úÖ Equipe de suporte treinada
‚úÖ Documenta√ß√£o atualizada

### Declara√ß√£o de Aprova√ß√£o

```
CERTIFICA√á√ÉO DE CONCLUS√ÉO DO UAT

Eu, abaixo assinado, certifico que:

1. O Plano de Testes de Aceita√ß√£o do Usu√°rio foi executado
   completamente conforme documentado.

2. Todos os crit√©rios de aceita√ß√£o foram atendidos.

3. A aplica√ß√£o PrediTest AI est√° pronta para produ√ß√£o.

4. Os riscos identificados foram mitigados ou aceitos.

5. A equipe est√° pronta para suportar a aplica√ß√£o.

Portanto, autorizo o go-live em produ√ß√£o.

Assinado:

________________________          _______________
Diretor de Inova√ß√£o              Data

________________________          _______________
Gerente de Projeto               Data

________________________          _______________
L√≠der de Testes                  Data
```

---

## üìû Contatos e Escala√ß√£o

### Estrutura de Escala√ß√£o

```
N√≠vel 1: Testador
‚îú‚îÄ Identifica problema
‚îî‚îÄ Documenta em ticket

N√≠vel 2: L√≠der de Testes
‚îú‚îÄ Revisa problema
‚îú‚îÄ Classifica severidade
‚îî‚îÄ Atribui ao Dev

N√≠vel 3: Dev Team
‚îú‚îÄ Analisa problema
‚îú‚îÄ Implementa corre√ß√£o
‚îî‚îÄ Testa solu√ß√£o

N√≠vel 4: Gerente de Projeto
‚îú‚îÄ Monitora progresso
‚îú‚îÄ Resolve bloqueadores
‚îî‚îÄ Comunica stakeholders

N√≠vel 5: Patrocinador
‚îú‚îÄ Toma decis√µes cr√≠ticas
‚îú‚îÄ Aprova extens√µes
‚îî‚îÄ Autoriza go-live
```

### Contatos Principais

| Papel | Nome | Email | Telefone |
|------|------|-------|----------|
| Patrocinador | [Nome] | [Email] | [Tel] |
| Gerente Projeto | [Nome] | [Email] | [Tel] |
| L√≠der Testes | [Nome] | [Email] | [Tel] |
| L√≠der Dev | [Nome] | [Email] | [Tel] |
| Suporte TI | [Nome] | [Email] | [Tel] |

---

## üìö Anexos

### Anexo A: Gloss√°rio de Termos

- **UAT**: User Acceptance Testing (Teste de Aceita√ß√£o do Usu√°rio)
- **TC**: Test Case (Caso de Teste)
- **PASS**: Teste passou conforme esperado
- **FAIL**: Teste falhou
- **Defeito**: Comportamento n√£o conforme
- **Severidade**: N√≠vel de impacto do defeito
- **Go-live**: Libera√ß√£o para produ√ß√£o
- **Rollback**: Revers√£o para vers√£o anterior

### Anexo B: Refer√™ncias

- [Documento Funcional](./Documentofuncional-Testesindustriaiseficientes.docx)
- [README.md](./README.md)
- [API Documentation](./docs/API.md)
- [Architecture](./docs/ARCHITECTURE.md)

### Anexo C: Ferramentas de Teste

- **Test Management**: TestRail / Jira
- **Bug Tracking**: Jira / Azure DevOps
- **Performance**: JMeter / LoadRunner
- **Security**: OWASP ZAP / Burp Suite
- **Monitoring**: Prometheus / Grafana

---

## üìÑ Hist√≥rico de Revis√µes

| Vers√£o | Data | Autor | Mudan√ßas |
|--------|------|-------|----------|
| 1.0 | 2025-10-30 | IA Manus | Vers√£o inicial |
| 1.1 | [Data] | [Autor] | [Mudan√ßas] |

---

**Vers√£o**: 1.0.0 | **Data**: Outubro 2025 | **Status**: Pronto para Execu√ß√£o

Desenvolvido com ‚ù§Ô∏è para a Nestl√© Brasil

